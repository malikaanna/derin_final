{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üçé Fruit Freshness: GAN vs VAE Kar≈üƒ±la≈ütƒ±rmasƒ± (Google Colab Versiyonu)\n",
                "\n",
                "Bu notebook, Fruit Freshness Classification veri seti √ºzerinde DCGAN ve VAE modellerinin kar≈üƒ±la≈ütƒ±rmalƒ± analizini i√ßerir.\n",
                "T√ºm kodlar (veri indirme, modeller, eƒüitim) bu notebook i√ßinde tanƒ±mlanmƒ±≈ütƒ±r.\n",
                "\n",
                "## ƒ∞√ßerik\n",
                "1. Kurulum ve K√ºt√ºphaneler\n",
                "2. Veri Seti ƒ∞ndirme (kagglehub)\n",
                "3. Yardƒ±mcƒ± Fonksiyonlar\n",
                "4. Model Mimarileri (VAE & DCGAN)\n",
                "5. VAE Eƒüitimi\n",
                "6. DCGAN Eƒüitimi\n",
                "7. Sonu√ßlar ve Kar≈üƒ±la≈ütƒ±rma"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Kurulum ve K√ºt√ºphaneler"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install kagglehub -q\n",
                "\n",
                "import os\n",
                "import shutil\n",
                "import random\n",
                "from pathlib import Path\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from tqdm.notebook import tqdm\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import DataLoader, random_split, Subset\n",
                "from torchvision import datasets, transforms\n",
                "from torchvision.utils import make_grid\n",
                "\n",
                "# Seed ayarlama (Tekrarlanabilirlik i√ßin)\n",
                "def set_seed(seed=42):\n",
                "    random.seed(seed)\n",
                "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    torch.cuda.manual_seed(seed)\n",
                "    torch.backends.cudnn.deterministic = True\n",
                "\n",
                "set_seed(42)\n",
                "\n",
                "# Device ayarƒ±\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Kullanƒ±lan cihaz: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Veri Seti ƒ∞ndirme"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import kagglehub\n",
                "\n",
                "print(\"Veri seti indiriliyor (kagglehub ile)...\")\n",
                "try:\n",
                "    # Veriyi indir\n",
                "    cache_path = kagglehub.dataset_download(\"sriramr/fruits-fresh-and-rotten-for-classification\")\n",
                "    print(f\"ƒ∞ndirilen yol: {cache_path}\")\n",
                "    \n",
                "    # Veri setini d√ºzenle\n",
                "    # Veri setinin i√ß yapƒ±sƒ±nƒ± kontrol edip doƒüru train klas√∂r√ºn√º buluyoruz\n",
                "    data_root = Path(cache_path)\n",
                "    train_dir = None\n",
                "    \n",
                "    # Olasƒ± yollarƒ± kontrol et\n",
                "    possible_paths = [\n",
                "        data_root / \"dataset\" / \"train\",\n",
                "        data_root / \"train\",\n",
                "        data_root\n",
                "    ]\n",
                "    \n",
                "    for path in possible_paths:\n",
                "        if path.exists() and any(path.iterdir()):\n",
                "            # ƒ∞√ßinde freshapples vb. klas√∂rler var mƒ± diye bak\n",
                "            if any((path / cls).exists() for cls in ['freshapples', 'rottenapples']):\n",
                "                train_dir = path\n",
                "                break\n",
                "    \n",
                "    if train_dir:\n",
                "        print(f\"Eƒüitim verisi bulundu: {train_dir}\")\n",
                "    else:\n",
                "        raise FileNotFoundError(\"Eƒüitim klas√∂r√º (train) bulunamadƒ±!\")\n",
                "        \n",
                "except Exception as e:\n",
                "    print(f\"Hata olu≈ütu: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Yardƒ±mcƒ± Fonksiyonlar (Dataloader & G√∂rselle≈ütirme)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# G√∂r√ºnt√º d√∂n√º≈ü√ºmleri\n",
                "def get_transforms(image_size=64):\n",
                "    return transforms.Compose([\n",
                "        transforms.Resize((image_size, image_size)),\n",
                "        transforms.ToTensor(),\n",
                "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # [-1, 1] aralƒ±ƒüƒ±na getirir\n",
                "    ])\n",
                "\n",
                "# Dataloader olu≈üturucu\n",
                "def create_dataloader(root_dir, batch_size=32, image_size=64, val_split=0.1):\n",
                "    transform = get_transforms(image_size)\n",
                "    \n",
                "    dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n",
                "    print(f\"Toplam g√∂r√ºnt√º sayƒ±sƒ±: {len(dataset)}\")\n",
                "    print(f\"Sƒ±nƒ±flar: {dataset.classes}\")\n",
                "    \n",
                "    # Train/Val split\n",
                "    val_size = int(len(dataset) * val_split)\n",
                "    train_size = len(dataset) - val_size\n",
                "    \n",
                "    train_dataset, val_dataset = random_split(\n",
                "        dataset, [train_size, val_size],\n",
                "        generator=torch.Generator().manual_seed(42)\n",
                "    )\n",
                "    \n",
                "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
                "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
                "    \n",
                "    return train_loader, val_loader\n",
                "\n",
                "# G√∂rselle≈ütirme fonksiyonlarƒ±\n",
                "def denormalize(tensor):\n",
                "    return (tensor + 1) / 2\n",
                "\n",
                "def show_images(images, nrow=8, title=None):\n",
                "    images = denormalize(images.cpu())\n",
                "    grid = make_grid(images, nrow=nrow, padding=2)\n",
                "    plt.figure(figsize=(10, 10))\n",
                "    plt.imshow(grid.permute(1, 2, 0))\n",
                "    plt.axis('off')\n",
                "    if title:\n",
                "        plt.title(title)\n",
                "    plt.show()\n",
                "\n",
                "# Veriyi y√ºkle\n",
                "train_loader, val_loader = create_dataloader(train_dir, batch_size=64, image_size=64)\n",
                "\n",
                "# √ñrnek bir batch g√∂ster\n",
                "sample_images, _ = next(iter(train_loader))\n",
                "show_images(sample_images[:16], nrow=4, title=\"Eƒüitim Verisinden √ñrnekler\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Mimarileri"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- VAE Modeli ---\n",
                "class VAE(nn.Module):\n",
                "    def __init__(self, latent_dim=128):\n",
                "        super(VAE, self).__init__()\n",
                "        self.latent_dim = latent_dim\n",
                "        \n",
                "        # Encoder\n",
                "        self.encoder = nn.Sequential(\n",
                "            nn.Conv2d(3, 32, 4, 2, 1), nn.BatchNorm2d(32), nn.LeakyReLU(0.2),\n",
                "            nn.Conv2d(32, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.LeakyReLU(0.2),\n",
                "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2),\n",
                "            nn.Conv2d(128, 256, 4, 2, 1), nn.BatchNorm2d(256), nn.LeakyReLU(0.2),\n",
                "        )\n",
                "        \n",
                "        self.fc_mu = nn.Linear(256*4*4, latent_dim)\n",
                "        self.fc_logvar = nn.Linear(256*4*4, latent_dim)\n",
                "        self.fc_decode = nn.Linear(latent_dim, 256*4*4)\n",
                "        \n",
                "        # Decoder\n",
                "        self.decoder = nn.Sequential(\n",
                "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.ReLU(),\n",
                "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.BatchNorm2d(64), nn.ReLU(),\n",
                "            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.BatchNorm2d(32), nn.ReLU(),\n",
                "            nn.ConvTranspose2d(32, 3, 4, 2, 1), nn.Tanh()\n",
                "        )\n",
                "        \n",
                "    def encode(self, x):\n",
                "        h = self.encoder(x)\n",
                "        h = h.view(h.size(0), -1)\n",
                "        return self.fc_mu(h), self.fc_logvar(h)\n",
                "        \n",
                "    def reparameterize(self, mu, logvar):\n",
                "        std = torch.exp(0.5 * logvar)\n",
                "        eps = torch.randn_like(std)\n",
                "        return mu + eps * std\n",
                "        \n",
                "    def decode(self, z):\n",
                "        h = self.fc_decode(z)\n",
                "        h = h.view(h.size(0), 256, 4, 4)\n",
                "        return self.decoder(h)\n",
                "        \n",
                "    def forward(self, x):\n",
                "        mu, logvar = self.encode(x)\n",
                "        z = self.reparameterize(mu, logvar)\n",
                "        return self.decode(z), mu, logvar\n",
                "\n",
                "def vae_loss_fn(recon_x, x, mu, logvar):\n",
                "    recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
                "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
                "    return recon_loss + kl_loss, recon_loss, kl_loss\n",
                "\n",
                "# --- DCGAN Modelleri ---\n",
                "def weights_init(m):\n",
                "    classname = m.__class__.__name__\n",
                "    if classname.find('Conv') != -1:\n",
                "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
                "    elif classname.find('BatchNorm') != -1:\n",
                "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
                "        nn.init.constant_(m.bias.data, 0)\n",
                "\n",
                "class Generator(nn.Module):\n",
                "    def __init__(self, noise_dim=100):\n",
                "        super(Generator, self).__init__()\n",
                "        self.main = nn.Sequential(\n",
                "            nn.ConvTranspose2d(noise_dim, 512, 4, 1, 0, bias=False), nn.BatchNorm2d(512), nn.ReLU(True),\n",
                "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False), nn.BatchNorm2d(256), nn.ReLU(True),\n",
                "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False), nn.BatchNorm2d(128), nn.ReLU(True),\n",
                "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False), nn.BatchNorm2d(64), nn.ReLU(True),\n",
                "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False), nn.Tanh()\n",
                "        )\n",
                "        self.apply(weights_init)\n",
                "\n",
                "    def forward(self, z):\n",
                "        return self.main(z)\n",
                "\n",
                "class Discriminator(nn.Module):\n",
                "    def __init__(self):\n",
                "        super(Discriminator, self).__init__()\n",
                "        self.main = nn.Sequential(\n",
                "            nn.Conv2d(3, 64, 4, 2, 1, bias=False), nn.LeakyReLU(0.2, inplace=True),\n",
                "            nn.Conv2d(64, 128, 4, 2, 1, bias=False), nn.BatchNorm2d(128), nn.LeakyReLU(0.2, inplace=True),\n",
                "            nn.Conv2d(128, 256, 4, 2, 1, bias=False), nn.BatchNorm2d(256), nn.LeakyReLU(0.2, inplace=True),\n",
                "            nn.Conv2d(256, 512, 4, 2, 1, bias=False), nn.BatchNorm2d(512), nn.LeakyReLU(0.2, inplace=True),\n",
                "            nn.Conv2d(512, 1, 4, 1, 0, bias=False), nn.Sigmoid()\n",
                "        )\n",
                "        self.apply(weights_init)\n",
                "\n",
                "    def forward(self, x):\n",
                "        return self.main(x)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. VAE Eƒüitimi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# VAE Ayarlarƒ±\n",
                "vae = VAE(latent_dim=128).to(device)\n",
                "vae_optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
                "vae_epochs = 20  # Demo i√ßin kƒ±sa tutuldu, artƒ±rƒ±labilir\n",
                "\n",
                "print(\"VAE eƒüitimi ba≈ülƒ±yor...\")\n",
                "vae_losses = []\n",
                "\n",
                "for epoch in range(vae_epochs):\n",
                "    vae.train()\n",
                "    total_loss = 0\n",
                "    for images, _ in tqdm(train_loader, desc=f\"VAE Epoch {epoch+1}/{vae_epochs}\", leave=False):\n",
                "        images = images.to(device)\n",
                "        \n",
                "        recon_images, mu, logvar = vae(images)\n",
                "        loss, _, _ = vae_loss_fn(recon_images, images, mu, logvar)\n",
                "        \n",
                "        vae_optimizer.zero_grad()\n",
                "        loss.backward()\n",
                "        vae_optimizer.step()\n",
                "        \n",
                "        total_loss += loss.item()\n",
                "    \n",
                "    avg_loss = total_loss / len(train_loader.dataset)\n",
                "    vae_losses.append(avg_loss)\n",
                "    print(f\"Epoch {epoch+1}: Loss {avg_loss:.4f}\")\n",
                "    \n",
                "    # Her 5 epochta bir √∂rnek g√∂ster\n",
                "    if (epoch + 1) % 5 == 0:\n",
                "        vae.eval()\n",
                "        with torch.no_grad():\n",
                "            z = torch.randn(16, 128).to(device)\n",
                "            samples = vae.decode(z)\n",
                "            show_images(samples, nrow=8, title=f\"VAE Samples Epoch {epoch+1}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. DCGAN Eƒüitimi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# DCGAN Ayarlarƒ±\n",
                "netG = Generator(noise_dim=100).to(device)\n",
                "netD = Discriminator().to(device)\n",
                "\n",
                "criterion = nn.BCELoss()\n",
                "optimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
                "optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
                "\n",
                "fixed_noise = torch.randn(64, 100, 1, 1, device=device)\n",
                "gan_epochs = 20\n",
                "\n",
                "print(\"DCGAN eƒüitimi ba≈ülƒ±yor...\")\n",
                "G_losses = []\n",
                "D_losses = []\n",
                "\n",
                "for epoch in range(gan_epochs):\n",
                "    for i, (data, _) in enumerate(tqdm(train_loader, desc=f\"GAN Epoch {epoch+1}/{gan_epochs}\", leave=False)):\n",
                "        # 1. Discriminator Eƒüitimi: log(D(x)) + log(1 - D(G(z)))\n",
                "        netD.zero_grad()\n",
                "        real_cpu = data.to(device)\n",
                "        b_size = real_cpu.size(0)\n",
                "        label = torch.full((b_size,), 1., dtype=torch.float, device=device)\n",
                "        \n",
                "        output = netD(real_cpu).view(-1)\n",
                "        errD_real = criterion(output, label)\n",
                "        errD_real.backward()\n",
                "        \n",
                "        noise = torch.randn(b_size, 100, 1, 1, device=device)\n",
                "        fake = netG(noise)\n",
                "        label.fill_(0.)\n",
                "        \n",
                "        output = netD(fake.detach()).view(-1)\n",
                "        errD_fake = criterion(output, label)\n",
                "        errD_fake.backward()\n",
                "        optimizerD.step()\n",
                "        \n",
                "        # 2. Generator Eƒüitimi: log(D(G(z)))\n",
                "        netG.zero_grad()\n",
                "        label.fill_(1.)  # Generator i√ßin hedef: Discriminator'ƒ± kandƒ±rmak\n",
                "        output = netD(fake).view(-1)\n",
                "        errG = criterion(output, label)\n",
                "        errG.backward()\n",
                "        optimizerG.step()\n",
                "        \n",
                "        G_losses.append(errG.item())\n",
                "        D_losses.append(errD_real.item() + errD_fake.item())\n",
                "\n",
                "    print(f\"Epoch {epoch+1}: Loss_D: {D_losses[-1]:.4f}, Loss_G: {G_losses[-1]:.4f}\")\n",
                "    \n",
                "    if (epoch + 1) % 5 == 0:\n",
                "        with torch.no_grad():\n",
                "            fake = netG(fixed_noise).detach().cpu()\n",
                "            show_images(fake, nrow=8, title=f\"DCGAN Samples Epoch {epoch+1}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Sonu√ßlar ve Kar≈üƒ±la≈ütƒ±rma"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Loss Grafikleri\n",
                "plt.figure(figsize=(15, 5))\n",
                "\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(vae_losses, label=\"VAE Loss\")\n",
                "plt.title(\"VAE Training Loss\")\n",
                "plt.legend()\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(G_losses, label=\"Generator\")\n",
                "plt.plot(D_losses, label=\"Discriminator\")\n",
                "plt.title(\"DCGAN Training Losses\")\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "# Yan Yana Kar≈üƒ±la≈ütƒ±rma\n",
                "vae.eval()\n",
                "netG.eval()\n",
                "\n",
                "with torch.no_grad():\n",
                "    # VAE'den √∂rnekler\n",
                "    z_vae = torch.randn(32, 128).to(device)\n",
                "    vae_samples = vae.decode(z_vae)\n",
                "    \n",
                "    # GAN'dan √∂rnekler\n",
                "    z_gan = torch.randn(32, 100, 1, 1).to(device)\n",
                "    gan_samples = netG(z_gan)\n",
                "\n",
                "print(\"VAE Sonu√ßlarƒ±:\")\n",
                "show_images(vae_samples, nrow=8)\n",
                "\n",
                "print(\"DCGAN Sonu√ßlarƒ±:\")\n",
                "show_images(gan_samples, nrow=8)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}