{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üçé Fruit Freshness: GAN vs VAE Kar≈üƒ±la≈ütƒ±rmasƒ±\n",
                "\n",
                "Bu notebook, Fruit Freshness Classification veri seti √ºzerinde DCGAN ve VAE modellerinin kar≈üƒ±la≈ütƒ±rmalƒ± analizini i√ßerir.\n",
                "\n",
                "## ƒ∞√ßerik\n",
                "1. Kurulum ve Veri Hazƒ±rlƒ±ƒüƒ±\n",
                "2. VAE Eƒüitimi\n",
                "3. DCGAN Eƒüitimi\n",
                "4. Model Kar≈üƒ±la≈ütƒ±rmasƒ±\n",
                "5. Sonu√ßlar ve Analiz"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Kurulum"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Google Colab i√ßin kurulum\n",
                "import sys\n",
                "IN_COLAB = 'google.colab' in sys.modules\n",
                "\n",
                "if IN_COLAB:\n",
                "    # Projeyi klonla (eƒüer GitHub'a y√ºklendiyse)\n",
                "    # !git clone https://github.com/username/Derin_Final.git\n",
                "    # %cd Derin_Final\n",
                "    \n",
                "    # Gerekli k√ºt√ºphaneleri y√ºkle\n",
                "    !pip install kaggle -q\n",
                "    \n",
                "    # Kaggle API anahtarƒ±nƒ± ayarla\n",
                "    # Kaggle'dan indirdiƒüiniz kaggle.json dosyasƒ±nƒ± y√ºkleyin\n",
                "    from google.colab import files\n",
                "    print(\"Kaggle API token dosyasƒ±nƒ± y√ºkleyin (kaggle.json):\")\n",
                "    # uploaded = files.upload()\n",
                "    # !mkdir -p ~/.kaggle\n",
                "    # !mv kaggle.json ~/.kaggle/\n",
                "    # !chmod 600 ~/.kaggle/kaggle.json"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Gerekli k√ºt√ºphaneleri import et\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader\n",
                "from torchvision import transforms\n",
                "from torchvision.utils import make_grid\n",
                "\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from pathlib import Path\n",
                "from tqdm.notebook import tqdm\n",
                "\n",
                "# Proje mod√ºllerini import et\n",
                "import sys\n",
                "sys.path.insert(0, '..')\n",
                "\n",
                "from models.vae import VAE, vae_loss\n",
                "from models.dcgan import Generator, Discriminator\n",
                "from utils.dataloader import get_dataloader, denormalize\n",
                "from utils.visualization import show_images, save_generated_images\n",
                "\n",
                "# Device ayarƒ±\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Veri Hazƒ±rlƒ±ƒüƒ±"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Veri setini indir (ilk √ßalƒ±≈ütƒ±rmada)\n",
                "# !kaggle datasets download -d sriramr/fruits-fresh-and-rotten-for-classification -p ../data --unzip"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Hiperparametreler\n",
                "BATCH_SIZE = 32\n",
                "IMAGE_SIZE = 64\n",
                "LATENT_DIM = 128  # VAE i√ßin\n",
                "NOISE_DIM = 100   # GAN i√ßin\n",
                "EPOCHS = 50\n",
                "LR = 0.0002"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Veri y√ºkleyicileri olu≈ütur\n",
                "train_loader, val_loader = get_dataloader(\n",
                "    batch_size=BATCH_SIZE,\n",
                "    image_size=IMAGE_SIZE,\n",
                "    num_workers=2\n",
                ")\n",
                "\n",
                "# √ñrnek g√∂r√ºnt√ºleri g√∂ster\n",
                "sample_batch, _ = next(iter(train_loader))\n",
                "show_images(sample_batch[:16], nrow=4, title=\"√ñrnek Eƒüitim G√∂r√ºnt√ºleri\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. VAE Eƒüitimi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# VAE modelini olu≈ütur\n",
                "vae = VAE(latent_dim=LATENT_DIM).to(device)\n",
                "vae_optimizer = optim.Adam(vae.parameters(), lr=LR, betas=(0.5, 0.999))\n",
                "\n",
                "# Parametre sayƒ±sƒ±\n",
                "vae_params = sum(p.numel() for p in vae.parameters())\n",
                "print(f\"VAE parameters: {vae_params:,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# VAE eƒüitim d√∂ng√ºs√º\n",
                "vae_history = {'loss': [], 'recon': [], 'kl': []}\n",
                "fixed_z_vae = torch.randn(16, LATENT_DIM, device=device)\n",
                "\n",
                "print(\"VAE Eƒüitimi Ba≈ülƒ±yor...\")\n",
                "for epoch in range(1, EPOCHS + 1):\n",
                "    vae.train()\n",
                "    epoch_loss, epoch_recon, epoch_kl = 0, 0, 0\n",
                "    \n",
                "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\")\n",
                "    for images, _ in pbar:\n",
                "        images = images.to(device)\n",
                "        \n",
                "        # Forward\n",
                "        recon, mu, logvar = vae(images)\n",
                "        loss, recon_loss, kl_loss = vae_loss(recon, images, mu, logvar)\n",
                "        \n",
                "        # Backward\n",
                "        vae_optimizer.zero_grad()\n",
                "        loss.backward()\n",
                "        vae_optimizer.step()\n",
                "        \n",
                "        epoch_loss += loss.item()\n",
                "        epoch_recon += recon_loss.item()\n",
                "        epoch_kl += kl_loss.item()\n",
                "        \n",
                "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
                "    \n",
                "    # Epoch ortalamalarƒ±\n",
                "    n = len(train_loader)\n",
                "    vae_history['loss'].append(epoch_loss / n)\n",
                "    vae_history['recon'].append(epoch_recon / n)\n",
                "    vae_history['kl'].append(epoch_kl / n)\n",
                "    \n",
                "    # Her 10 epoch'ta √∂rnek √ºret\n",
                "    if epoch % 10 == 0 or epoch == 1:\n",
                "        vae.eval()\n",
                "        with torch.no_grad():\n",
                "            samples = vae.decode(fixed_z_vae)\n",
                "        show_images(samples, nrow=4, title=f\"VAE - Epoch {epoch}\")\n",
                "\n",
                "print(\"VAE Eƒüitimi Tamamlandƒ±!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# VAE loss grafikleri\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
                "\n",
                "axes[0].plot(vae_history['loss'])\n",
                "axes[0].set_title('Total Loss')\n",
                "axes[0].set_xlabel('Epoch')\n",
                "\n",
                "axes[1].plot(vae_history['recon'])\n",
                "axes[1].set_title('Reconstruction Loss')\n",
                "axes[1].set_xlabel('Epoch')\n",
                "\n",
                "axes[2].plot(vae_history['kl'])\n",
                "axes[2].set_title('KL Divergence')\n",
                "axes[2].set_xlabel('Epoch')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. DCGAN Eƒüitimi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# DCGAN modellerini olu≈ütur\n",
                "generator = Generator(noise_dim=NOISE_DIM).to(device)\n",
                "discriminator = Discriminator().to(device)\n",
                "\n",
                "criterion = nn.BCELoss()\n",
                "g_optimizer = optim.Adam(generator.parameters(), lr=LR, betas=(0.5, 0.999))\n",
                "d_optimizer = optim.Adam(discriminator.parameters(), lr=LR, betas=(0.5, 0.999))\n",
                "\n",
                "g_params = sum(p.numel() for p in generator.parameters())\n",
                "d_params = sum(p.numel() for p in discriminator.parameters())\n",
                "print(f\"Generator parameters: {g_params:,}\")\n",
                "print(f\"Discriminator parameters: {d_params:,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# DCGAN eƒüitim d√∂ng√ºs√º\n",
                "gan_history = {'d_loss': [], 'g_loss': [], 'd_real': [], 'd_fake': []}\n",
                "fixed_z_gan = torch.randn(16, NOISE_DIM, 1, 1, device=device)\n",
                "\n",
                "print(\"DCGAN Eƒüitimi Ba≈ülƒ±yor...\")\n",
                "for epoch in range(1, EPOCHS + 1):\n",
                "    generator.train()\n",
                "    discriminator.train()\n",
                "    \n",
                "    epoch_d_loss, epoch_g_loss = 0, 0\n",
                "    epoch_d_real, epoch_d_fake = 0, 0\n",
                "    \n",
                "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\")\n",
                "    for images, _ in pbar:\n",
                "        batch_size = images.size(0)\n",
                "        images = images.to(device)\n",
                "        \n",
                "        real_labels = torch.full((batch_size, 1, 1, 1), 0.9, device=device)\n",
                "        fake_labels = torch.full((batch_size, 1, 1, 1), 0.0, device=device)\n",
                "        \n",
                "        # Train Discriminator\n",
                "        d_optimizer.zero_grad()\n",
                "        output_real = discriminator(images)\n",
                "        d_loss_real = criterion(output_real, real_labels)\n",
                "        \n",
                "        noise = torch.randn(batch_size, NOISE_DIM, 1, 1, device=device)\n",
                "        fake_images = generator(noise)\n",
                "        output_fake = discriminator(fake_images.detach())\n",
                "        d_loss_fake = criterion(output_fake, fake_labels)\n",
                "        \n",
                "        d_loss = d_loss_real + d_loss_fake\n",
                "        d_loss.backward()\n",
                "        d_optimizer.step()\n",
                "        \n",
                "        # Train Generator\n",
                "        g_optimizer.zero_grad()\n",
                "        noise = torch.randn(batch_size, NOISE_DIM, 1, 1, device=device)\n",
                "        fake_images = generator(noise)\n",
                "        output = discriminator(fake_images)\n",
                "        g_loss = criterion(output, real_labels)\n",
                "        g_loss.backward()\n",
                "        g_optimizer.step()\n",
                "        \n",
                "        epoch_d_loss += d_loss.item()\n",
                "        epoch_g_loss += g_loss.item()\n",
                "        epoch_d_real += output_real.mean().item()\n",
                "        epoch_d_fake += output.mean().item()\n",
                "        \n",
                "        pbar.set_postfix({'D': f'{d_loss.item():.4f}', 'G': f'{g_loss.item():.4f}'})\n",
                "    \n",
                "    # Epoch ortalamalarƒ±\n",
                "    n = len(train_loader)\n",
                "    gan_history['d_loss'].append(epoch_d_loss / n)\n",
                "    gan_history['g_loss'].append(epoch_g_loss / n)\n",
                "    gan_history['d_real'].append(epoch_d_real / n)\n",
                "    gan_history['d_fake'].append(epoch_d_fake / n)\n",
                "    \n",
                "    # Her 10 epoch'ta √∂rnek √ºret\n",
                "    if epoch % 10 == 0 or epoch == 1:\n",
                "        generator.eval()\n",
                "        with torch.no_grad():\n",
                "            samples = generator(fixed_z_gan)\n",
                "        show_images(samples, nrow=4, title=f\"DCGAN - Epoch {epoch}\")\n",
                "\n",
                "print(\"DCGAN Eƒüitimi Tamamlandƒ±!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# GAN loss grafikleri\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "\n",
                "axes[0].plot(gan_history['d_loss'], label='Discriminator')\n",
                "axes[0].plot(gan_history['g_loss'], label='Generator')\n",
                "axes[0].set_title('GAN Losses')\n",
                "axes[0].set_xlabel('Epoch')\n",
                "axes[0].legend()\n",
                "\n",
                "axes[1].plot(gan_history['d_real'], label='D(x)')\n",
                "axes[1].plot(gan_history['d_fake'], label='D(G(z))')\n",
                "axes[1].set_title('Discriminator Outputs')\n",
                "axes[1].set_xlabel('Epoch')\n",
                "axes[1].legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model Kar≈üƒ±la≈ütƒ±rmasƒ±"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Modelleri eval moduna al\n",
                "vae.eval()\n",
                "generator.eval()\n",
                "\n",
                "# √ñrnek √ºret\n",
                "with torch.no_grad():\n",
                "    vae_samples = vae.sample(16, device)\n",
                "    gan_samples = generator.generate(16, device)\n",
                "    real_samples = next(iter(val_loader))[0][:16]\n",
                "\n",
                "# Kar≈üƒ±la≈ütƒ±rmalƒ± g√∂rselle≈ütirme\n",
                "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
                "\n",
                "for ax, (images, title) in zip(axes, [\n",
                "    (real_samples, \"Ger√ßek G√∂r√ºnt√ºler\"),\n",
                "    (vae_samples, \"VAE √úretimi\"),\n",
                "    (gan_samples, \"DCGAN √úretimi\")\n",
                "]):\n",
                "    if images.min() < 0:\n",
                "        images = denormalize(images)\n",
                "    grid = make_grid(images.cpu(), nrow=4, padding=2)\n",
                "    ax.imshow(grid.permute(1, 2, 0).numpy())\n",
                "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
                "    ax.axis('off')\n",
                "\n",
                "plt.suptitle(\"Model Kar≈üƒ±la≈ütƒ±rmasƒ±\", fontsize=18, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.savefig('../outputs/comparison/notebook_comparison.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Sonu√ß ve Analiz\n",
                "\n",
                "### G√∂rsel Kalite\n",
                "- **VAE**: √úretilen g√∂r√ºnt√ºler genellikle daha bulanƒ±k olur √ß√ºnk√º MSE loss kullanƒ±lƒ±r.\n",
                "- **GAN**: Daha keskin ve detaylƒ± g√∂r√ºnt√ºler √ºretir, adversarial training sayesinde.\n",
                "\n",
                "### √áe≈üitlilik\n",
                "- **VAE**: Latent space'in tamamƒ±nƒ± kullandƒ±ƒüƒ± i√ßin √ße≈üitlilik genellikle daha y√ºksek.\n",
                "- **GAN**: Mode collapse riski vardƒ±r, bazƒ± modlar √∂ƒürenilmeyebilir.\n",
                "\n",
                "### Eƒüitim Kararlƒ±lƒ±ƒüƒ±\n",
                "- **VAE**: Kararlƒ± eƒüitim, loss s√ºrekli azalƒ±r.\n",
                "- **GAN**: Generator ve Discriminator arasƒ±nda denge gerektirir, dengesiz olabilir."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Modelleri kaydet\n",
                "torch.save(vae.state_dict(), '../checkpoints/vae_notebook.pt')\n",
                "torch.save(generator.state_dict(), '../checkpoints/generator_notebook.pt')\n",
                "print(\"Modeller kaydedildi!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}